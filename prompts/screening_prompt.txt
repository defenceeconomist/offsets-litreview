
## Screening prompt

**Role**
You are screening an academic or policy document for inclusion in a realist evidence synthesis and comparative case-mapping study on **defence offsets / industrial participation and alliance outcomes**.

**Task**
Read the document and evaluate it against the criteria below.
Return **only** a JSON object that conforms exactly to the output schema provided.
Do **not** add commentary outside the schema.

**Definitions (apply consistently)**

* *Offsets / industrial participation* include: offsets, industrial participation, industrial cooperation, IRB/ITB, localisation, workshare, technology transfer, licensed production, co-production, co-development, supply-chain integration, sustainment/MRO collaboration.
* *Alliance-relevant outcomes* include: interoperability, standardisation, readiness, delivery speed, sustainment, security or resilience of supply, multinational programme participation, rapid contribution to allied operations, or partnership frictions (delays, disputes, supplier withdrawal, export-control deadlock).
* *Mechanism* means a causal process explaining **how** the policy produces effects (not just correlation or assertion).
* *Context* refers to conditions such as policy design, institutional setting, technology sensitivity, export controls, domestic industrial maturity, or multinational procurement setting.

---

### Screening questions

Evaluate each item using the allowed values only.

**A. Core relevance**

1. Does the document substantially address defence offsets or industrial participation policy?
2. Does it address alliance- or partnership-relevant outcomes?
3. Does it identify or imply causal mechanisms linking policy to outcomes?
4. Does it specify relevant contextual conditions?

**B. Comparative and case evidence**
5. Does it provide positive or mixed cases where offsets coexist with deep allied industrial collaboration?
6. Does it document offset-related risks, frictions, or failures affecting partnerships or alliances?

**C. Evidence quality and usability**
7. What is the dominant evidence type and transparency level?
8. Can context–mechanism–outcome (CMO) elements be extracted with reasonable confidence?

---

### Decision rule (apply mechanically)

* **Include**: Questions 1–3 = “Yes”, and at least one of Questions 5 or 6 = “Yes” or “Partial”.
* **Include_contextual**: Question 1 = “Yes”, but Question 3 = “Partial” or “No”, and the document provides useful descriptive, legal, or policy context.
* **Exclude**: Question 1 = “No”, or alliance/partnership relevance is absent.

---

## Output schema (JSON only)

```json
{
  "metadata": {
    "title": "string or null",
    "author_year": "string or null",
    "document_type": "academic | policy | audit | legal | think_tank | commentary | other | unknown"
  },
  "screening": {
    "addresses_offsets_policy": "Yes | Partial | No",
    "addresses_alliance_outcomes": "Yes | Partial | No",
    "identifies_mechanisms": "Yes | Partial | No",
    "specifies_contextual_conditions": "Yes | Partial | No",
    "positive_or_mixed_cases": "Yes | Partial | No",
    "negative_or_friction_cases": "Yes | Partial | No"
  },
  "evidence_assessment": {
    "evidence_type": "empirical_case | comparative_analysis | audit_evaluation | legal_policy_analysis | secondary_synthesis | commentary_advocacy | mixed | unclear",
    "transparency_level": "High | Medium | Low",
    "cmo_extractability": "High | Medium | Low"
  },
  "analytic_notes": {
    "key_contexts": [
      "string"
    ],
    "key_mechanisms": [
      "string"
    ],
    "key_outcomes": [
      "string"
    ],
    "noted_risks_or_mitigations": [
      "string"
    ]
  },
  "decision": {
    "inclusion_decision": "Include | Include_contextual | Exclude",
    "confidence": "High | Medium | Low",
    "exclusion_reason": "string or null"
  }
}
```
